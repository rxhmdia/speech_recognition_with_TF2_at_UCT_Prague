{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/text/word_embeddings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_size = 5\n",
    "\n",
    "embedding_layer = layers.Embedding(vocab_size, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0275739 , -0.01354999,  0.01476267,  0.0234868 , -0.03942246],\n",
       "       [ 0.02769193,  0.00878152,  0.03697341,  0.00128802,  0.0141011 ],\n",
       "       [ 0.00259596, -0.04183214, -0.02993209,  0.00785676, -0.03427104]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([1, 2, 3]))\n",
    "result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape  # (samples, sequence_length, embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sideroad - loading raw text into a word vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATHS = [\"b:/!DATASETS/oral2013/transcripts_debug/labels.txt\", \n",
    "              \"b:/!DATASETS/PDTSC/transcripts_debug/labels.txt\"]\n",
    "ENCODING = \"windows-1250\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeler(example, index):\n",
    "  return example, tf.cast(index, tf.int64)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data_sets = []\n",
    "for i, file_path in enumerate(FILE_PATHS):\n",
    "    lines_dataset = tf.data.TextLineDataset(file_path)\n",
    "    labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\n",
    "    labeled_data_sets.append(labeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmm to nevim vůbec co se jak se mi to podařilo\n",
      "ale já sem si myslela že zejtra nemám rehabilitaci fakt sem vo tom byla přesvědčená a zistila sem že ji mám\n",
      "ty ji máš každej den\n",
      "no teď budu mít až do osumnáctýho ji budu mít každej den takový intenzivní a mám pocit\n",
      "že mě to asi zabije\n"
     ]
    }
   ],
   "source": [
    "for ex, lab in labeled_data_sets[0].take(5):\n",
    "    print(ex.numpy().decode(ENCODING))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 64\n",
    "TAKE_SIZE = 5000\n",
    "\n",
    "all_labeled_data = labeled_data_sets[0]\n",
    "for labeled_dataset in labeled_data_sets[1:]:\n",
    "  all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n",
    "  \n",
    "all_labeled_data = all_labeled_data.shuffle(\n",
    "    BUFFER_SIZE, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na této fotografii jsou mí rodiče při svatbě bylo to v roce devatenáct set třicet šest no byli to už ne úplně mladí lidé mamince bylo asi třicet tři let a tatínkovi bylo asi třicet osum\n",
      "dyž sem jednou uvažovala že bych šla ke zpovědi k salvátorovi tak sem si zkusila stáhnout jejich zpovědní zrcadlo a zjistila sem že na to sem asi moc hloupá\n",
      "tak na téhle fotce jsem já s manželkou sousedy a jedním kamarádem je to výlet důchodců a někde z restaurace p při občerstvení\n",
      "asi no\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "for ex, lab in all_labeled_data.take(5):\n",
    "    print(ex.numpy().decode(ENCODING))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3923"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "vocabulary_set = set()\n",
    "for text_tensor, _ in all_labeled_data:\n",
    "  some_tokens = tokenizer.tokenize(text_tensor.numpy().decode(ENCODING))\n",
    "  vocabulary_set.update(some_tokens)\n",
    "\n",
    "vocab_size = len(vocabulary_set)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na této fotografii jsou mí rodiče při svatbě bylo to v roce devatenáct set třicet šest no byli to už ne úplně mladí lidé mamince bylo asi třicet tři let a tatínkovi bylo asi třicet osum\n"
     ]
    }
   ],
   "source": [
    "example_text = next(iter(all_labeled_data))[0].numpy().decode(ENCODING)\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[281, 3103, 2681, 2332, 2741, 3539, 3522, 2371, 2390, 3704, 3471, 470, 2031, 1186, 2970, 3403, 1452, 3053, 3704, 433, 816, 1032, 2676, 3493, 240, 2390, 3211, 2970, 2664, 226, 3137, 1118, 2390, 3211, 2970, 350]\n"
     ]
    }
   ],
   "source": [
    "encoded_example = encoder.encode(example_text)\n",
    "print(encoded_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text_tensor, label):\n",
    "    encoded_text = encoder.encode(text_tensor.numpy().decode(ENCODING))\n",
    "    return encoded_text, label\n",
    "\n",
    "def encode_map_fn(text, label):\n",
    "    # py_func doesn't set the shape of the returned tensors.\n",
    "    encoded_text, label = tf.py_function(encode, \n",
    "                                       inp=[text, label], \n",
    "                                       Tout=(tf.int64, tf.int64))\n",
    "    encoded_text.set_shape([None])\n",
    "    label.set_shape([])\n",
    "    \n",
    "    return encoded_text, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_encoded_data = all_labeled_data.map(encode_map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 281 3103 2681 2332 2741 3539 3522 2371 2390 3704 3471  470 2031 1186\n",
      " 2970 3403 1452 3053 3704  433  816 1032 2676 3493  240 2390 3211 2970\n",
      " 2664  226 3137 1118 2390 3211 2970  350], shape=(36,), dtype=int64) tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for ex, lab in all_encoded_data.take(1):\n",
    "    print(ex, lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
